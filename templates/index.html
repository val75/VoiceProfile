<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Voice Profile Builder</title>
  <style>
    body {
      font-family: sans-serif;
      background: #f5f6fa;
      margin: 0;
      padding: 1rem;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    h1 { color: #333; }
    button {
      background: #007bff;
      color: white;
      border: none;
      padding: 0.75rem 1.25rem;
      border-radius: 6px;
      font-size: 1rem;
      cursor: pointer;
    }
    button:disabled {
      background: #ccc;
    }
    #output {
      margin-top: 1rem;
      width: 90%;
      max-width: 600px;
      background: #fff;
      border-radius: 8px;
      padding: 1rem;
      box-shadow: 0 2px 6px rgba(0,0,0,0.1);
    }
    pre {
      white-space: pre-wrap;
      word-wrap: break-word;
    }
  </style>
</head>
<body>
  <h1>üé§ Voice Profile Builder</h1>
  <p>Press record, describe your job or skills, then stop to upload.</p>

  <button id="recordBtn">Start Recording</button>
  <button id="stopBtn" disabled>Stop & Upload</button>

  <div id="output"></div>

  <script>
    let mediaRecorder;
    let audioChunks = [];

    const recordBtn = document.getElementById("recordBtn");
    const stopBtn = document.getElementById("stopBtn");
    const output = document.getElementById("output");

    recordBtn.onclick = async () => {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream);
      audioChunks = [];

      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
      mediaRecorder.onstop = uploadAudio;

      mediaRecorder.start();
      recordBtn.disabled = true;
      stopBtn.disabled = false;
      output.innerHTML = "<p>Recording... üéôÔ∏è</p>";
    };

    stopBtn.onclick = () => {
      mediaRecorder.stop();
      recordBtn.disabled = false;
      stopBtn.disabled = true;
      output.innerHTML = "<p>Processing...</p>";
    };

    async function uploadAudio() {
      const blob = new Blob(audioChunks, { type: "audio/webm" });
      const formData = new FormData();
      formData.append("file", blob, "recording.webm");

      try {
        const response = await fetch("/voice/upload", { method: "POST", body: formData });
        const data = await response.json();
        output.innerHTML = `<h3>Transcript:</h3><pre>${data.transcript}</pre>`;

        // Send transcript to NLP parser
        const nlpResponse = await fetch("/builder/parse", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text: data.transcript })
        });
        const structured = await nlpResponse.json();
        output.innerHTML += `<h3>Extracted Data:</h3><pre>${JSON.stringify(structured, null, 2)}</pre>`;
      } catch (err) {
        output.innerHTML = `<p style="color:red;">Error: ${err}</p>`;
      }
    }
  </script>
</body>
</html>
